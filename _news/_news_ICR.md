---
layout: post
date: 2024-10-15
inline: true
---
Check out our recent work [Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers](http://arxiv.org/abs/2410.02642), where we propose In-context Re-ranking (ICR) that performs re-ranking with LLMs using only O(1) forward passes!